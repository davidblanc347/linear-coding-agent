# Analyse des Outils MCP Server

**Date**: 2026-01-09
**Fichier**: `generations/library_rag/mcp_server.py`
**Total**: 18 outils MCP

## Vue d'ensemble

Le serveur MCP (Model Context Protocol) expose **18 outils** organis√©s en **3 cat√©gories** :

1. **Syst√®me** (1 outil) - Sant√© et diagnostics
2. **Library RAG** (8 outils) - Ingestion et recherche de textes philosophiques
3. **Memory** (9 outils) - Syst√®me de m√©moire conversationnelle

---

## üîß Cat√©gorie 1: Syst√®me (1 outil)

### 1. `ping()`
**Type**: Health check
**Param√®tres**: Aucun
**Retour**: Message de statut

**Description**: V√©rification que le serveur MCP est actif et r√©pond.

**Exemple**:
```python
ping()
# ‚Üí "Library RAG MCP Server is running!"
```

---

## üìö Cat√©gorie 2: Library RAG (8 outils)

### Outils d'Ingestion (1)

#### 2. `parse_pdf(pdf_path)`
**Type**: Ingestion PDF
**Collection cible**: Work, Chunk_v2, Summary_v2

**Param√®tres**:
- `pdf_path` (str): Chemin local ou URL vers le PDF

**Configuration pr√©-optimis√©e** (fixe):
- LLM: Mistral API (mistral-medium-latest)
- OCR: Avec annotations (meilleure TOC)
- Chunking: S√©mantique LLM (unit√©s argumentatives)
- Ingestion: Automatique dans Weaviate

**Retour**:
```json
{
  "success": true,
  "document_name": "platon-menon",
  "source_id": "platon-menon",
  "pages": 120,
  "chunks_count": 456,
  "cost_ocr": 0.36,
  "cost_llm": 0.08,
  "cost_total": 0.44,
  "output_dir": "output/platon-menon",
  "metadata": {
    "title": "M√©non",
    "author": "Platon",
    "year": -380,
    "language": "fr"
  }
}
```

**Processus** (10 √©tapes):
1. OCR Mistral avec annotations
2. Construction Markdown
3. Extraction images
4. LLM extraction m√©tadonn√©es
5. LLM extraction TOC
6. LLM classification sections
7. LLM chunking s√©mantique
8. Nettoyage chunks
9. LLM validation + concepts
10. Ingestion Weaviate + GPU vectorisation

---

### Outils de Recherche (7)

#### 3. `search_chunks(query, limit, min_similarity, author_filter, work_filter, language_filter)`
**Type**: Recherche s√©mantique
**Collection**: Chunk_v2 (5,372 chunks)

**Param√®tres**:
- `query` (str): Requ√™te en langage naturel
- `limit` (int): Nombre de r√©sultats (1-100, d√©faut 10)
- `min_similarity` (float): Seuil similarit√© 0-1 (d√©faut 0.0)
- `author_filter` (str|None): Filtrer par auteur
- `work_filter` (str|None): Filtrer par ≈ìuvre
- `language_filter` (str|None): Filtrer par langue (fr, en, etc.)

**Retour**:
```json
{
  "results": [
    {
      "text": "La vertu est-elle enseignable...",
      "work": {
        "title": "M√©non",
        "author": "Platon"
      },
      "section_path": "Premi√®re partie > Dialogue initial",
      "similarity": 0.87,
      "language": "fr"
    }
  ],
  "total_count": 10,
  "query": "la vertu peut-elle s'enseigner"
}
```

**Usage**:
- Recherche s√©mantique dans tous les textes
- Filtrage par auteur/≈ìuvre/langue
- Contr√¥le du seuil de similarit√©

---

#### 4. `search_summaries(query, limit, min_level, max_level)`
**Type**: Recherche s√©mantique (haut niveau)
**Collection**: Summary_v2 (114 r√©sum√©s)

**Param√®tres**:
- `query` (str): Requ√™te en langage naturel
- `limit` (int): Nombre de r√©sultats (d√©faut 10)
- `min_level` (int|None): Niveau minimum (1=chapitre)
- `max_level` (int|None): Niveau maximum (3=sous-section)

**Retour**:
```json
{
  "results": [
    {
      "title": "Dialogue sur la vertu",
      "text": "Ce chapitre explore la question...",
      "section_path": "Premi√®re partie",
      "level": 1,
      "concepts": ["vertu", "enseignement", "connaissance"],
      "chunks_count": 45
    }
  ],
  "total_count": 5,
  "query": "dialogue sur la vertu"
}
```

**Usage**:
- Vue d'ensemble des chapitres/sections
- Recherche par niveau hi√©rarchique
- Navigation structurelle

---

#### 5. `get_document(source_id, include_chunks, include_toc)`
**Type**: R√©cup√©ration document
**Collections**: Work, Chunk_v2

**Param√®tres**:
- `source_id` (str): Identifiant du document
- `include_chunks` (bool): Inclure les chunks (d√©faut False)
- `include_toc` (bool): Inclure la TOC (d√©faut False)

**Retour**:
```json
{
  "source_id": "platon-menon",
  "work": {
    "title": "M√©non",
    "author": "Platon",
    "year": -380,
    "language": "fr"
  },
  "chunks_count": 456,
  "chunks": [...],  // Si include_chunks=true
  "toc": [...]      // Si include_toc=true
}
```

**Usage**:
- R√©cup√©rer m√©tadonn√©es d'un document
- Charger tous les chunks d'un document
- Obtenir la structure (TOC)

---

#### 6. `list_documents(limit, author_filter, language_filter)`
**Type**: Liste documents
**Collection**: Work (19 ≈ìuvres)

**Param√®tres**:
- `limit` (int): Nombre max de r√©sultats (d√©faut 50)
- `author_filter` (str|None): Filtrer par auteur
- `language_filter` (str|None): Filtrer par langue

**Retour**:
```json
{
  "documents": [
    {
      "source_id": "platon-menon",
      "title": "M√©non",
      "author": "Platon",
      "language": "fr",
      "year": -380,
      "chunks_count": 456
    }
  ],
  "total_count": 19
}
```

**Usage**:
- Explorer le catalogue
- Lister les ≈ìuvres d'un auteur
- Filtrer par langue

---

#### 7. `get_chunks_by_document(source_id, limit, offset)`
**Type**: R√©cup√©ration chunks
**Collection**: Chunk_v2

**Param√®tres**:
- `source_id` (str): Identifiant du document
- `limit` (int): Nombre de chunks (d√©faut 50)
- `offset` (int): Position de d√©part (d√©faut 0)

**Retour**:
```json
{
  "source_id": "platon-menon",
  "chunks": [
    {
      "text": "Socrate : Peux-tu me dire...",
      "section_path": "Premi√®re partie",
      "order_index": 0,
      "unit_type": "argument"
    }
  ],
  "total_count": 456,
  "offset": 0,
  "limit": 50
}
```

**Usage**:
- Parcourir s√©quentiellement un document
- Pagination des chunks
- Lecture structur√©e

---

#### 8. `filter_by_author(author, limit)`
**Type**: Filtrage par auteur
**Collections**: Work, Chunk_v2

**Param√®tres**:
- `author` (str): Nom de l'auteur
- `limit` (int): Nombre max de r√©sultats (d√©faut 100)

**Retour**:
```json
{
  "author": "Platon",
  "works": [
    {
      "title": "M√©non",
      "chunks_count": 456
    },
    {
      "title": "La R√©publique",
      "chunks_count": 892
    }
  ],
  "total_works": 2,
  "total_chunks": 1348
}
```

**Usage**:
- Bibliographie d'un auteur
- Statistiques par auteur
- Exploration par corpus

---

#### 9. `delete_document(source_id, confirm)`
**Type**: Suppression
**Collections**: Work, Chunk_v2, Summary_v2

**Param√®tres**:
- `source_id` (str): Identifiant du document
- `confirm` (bool): Confirmation obligatoire (d√©faut False)

**Retour**:
```json
{
  "success": true,
  "source_id": "platon-menon",
  "deleted_chunks": 456,
  "deleted_summaries": 12,
  "deleted_work": true
}
```

**Usage**:
- Supprimer un document du syst√®me
- Nettoyage base de donn√©es
- R√©-ingestion apr√®s modification

**‚ö†Ô∏è S√©curit√©**: N√©cessite `confirm=true` explicite.

---

## üß† Cat√©gorie 3: Memory (9 outils)

### Outils Thought (3)

#### 10. `add_thought(content, thought_type, trigger, concepts, privacy_level)`
**Type**: Ajout pens√©e
**Collection**: Thought (104 pens√©es)

**Param√®tres**:
- `content` (str): Contenu de la pens√©e
- `thought_type` (str): Type (reflection, question, intuition, observation)
- `trigger` (str|None): D√©clencheur
- `concepts` (list[str]): Concepts li√©s
- `privacy_level` (str): Niveau (private, shared, public)

**Retour**:
```json
{
  "success": true,
  "thought_id": "uuid-xxxx",
  "timestamp": "2026-01-09T10:30:00Z"
}
```

**Usage**:
- Capturer insights et r√©flexions
- Construire base de connaissance personnelle
- Tracer √©volution de la pens√©e

---

#### 11. `search_thoughts(query, limit, thought_type_filter)`
**Type**: Recherche s√©mantique
**Collection**: Thought

**Param√®tres**:
- `query` (str): Requ√™te en langage naturel
- `limit` (int): Nombre de r√©sultats (d√©faut 10)
- `thought_type_filter` (str|None): Filtrer par type

**Retour**:
```json
{
  "results": [
    {
      "content": "Vector databases enable semantic search...",
      "thought_type": "observation",
      "concepts": ["weaviate", "embeddings"],
      "timestamp": "2026-01-08T15:20:00Z",
      "similarity": 0.92
    }
  ],
  "total_count": 10
}
```

**Usage**:
- Recherche dans ses pens√©es
- Retrouver insights pass√©s
- Connexions s√©mantiques

---

#### 12. `get_thought(uuid)`
**Type**: R√©cup√©ration pens√©e
**Collection**: Thought

**Param√®tres**:
- `uuid` (str): UUID de la pens√©e

**Retour**:
```json
{
  "uuid": "uuid-xxxx",
  "content": "...",
  "thought_type": "observation",
  "trigger": "Research session",
  "concepts": ["weaviate"],
  "privacy_level": "private",
  "timestamp": "2026-01-08T15:20:00Z"
}
```

**Usage**:
- R√©cup√©rer une pens√©e sp√©cifique
- Acc√®s direct par ID

---

### Outils Message (3)

#### 13. `add_message(content, role, conversation_id, order_index)`
**Type**: Ajout message
**Collection**: Message (380 messages)

**Param√®tres**:
- `content` (str): Contenu du message
- `role` (str): R√¥le (user, assistant, system)
- `conversation_id` (str): ID de la conversation
- `order_index` (int): Position dans la conversation

**Retour**:
```json
{
  "success": true,
  "message_id": "uuid-xxxx",
  "conversation_id": "chat_2026_01_09",
  "timestamp": "2026-01-09T10:30:00Z"
}
```

**Usage**:
- Ajouter message √† une conversation
- Construire historique
- Tracer dialogue

---

#### 14. `get_messages(conversation_id, limit)`
**Type**: R√©cup√©ration messages
**Collection**: Message

**Param√®tres**:
- `conversation_id` (str): ID de la conversation
- `limit` (int): Nombre max de messages (d√©faut 50)

**Retour**:
```json
{
  "conversation_id": "chat_2026_01_09",
  "messages": [
    {
      "content": "Explain transformers...",
      "role": "user",
      "order_index": 0,
      "timestamp": "2026-01-09T10:00:00Z"
    },
    {
      "content": "Transformers are neural networks...",
      "role": "assistant",
      "order_index": 1,
      "timestamp": "2026-01-09T10:01:00Z"
    }
  ],
  "total_count": 2
}
```

**Usage**:
- Charger historique conversation
- Contexte pour continuation
- Analyse conversationnelle

---

#### 15. `search_messages(query, limit, conversation_id_filter)`
**Type**: Recherche s√©mantique
**Collection**: Message

**Param√®tres**:
- `query` (str): Requ√™te en langage naturel
- `limit` (int): Nombre de r√©sultats (d√©faut 10)
- `conversation_id_filter` (str|None): Filtrer par conversation

**Retour**:
```json
{
  "results": [
    {
      "content": "Transformers use self-attention...",
      "role": "assistant",
      "conversation_id": "chat_2026_01_09",
      "timestamp": "2026-01-09T10:01:00Z",
      "similarity": 0.94
    }
  ],
  "total_count": 10
}
```

**Usage**:
- Rechercher dans l'historique
- Retrouver r√©ponses pass√©es
- Analyse transversale conversations

---

### Outils Conversation (3)

#### 16. `get_conversation(conversation_id)`
**Type**: R√©cup√©ration conversation
**Collection**: Conversation (12 conversations)

**Param√®tres**:
- `conversation_id` (str): ID de la conversation

**Retour**:
```json
{
  "conversation_id": "chat_2026_01_09",
  "title": "Discussion on AI transformers",
  "category": "technical",
  "summary": "Explained transformer architecture...",
  "tags": ["AI", "transformers", "architecture"],
  "message_count": 24,
  "timestamp": "2026-01-09T10:00:00Z"
}
```

**Usage**:
- M√©tadonn√©es conversation
- Vue d'ensemble
- Navigation conversations

---

#### 17. `search_conversations(query, limit, category_filter)`
**Type**: Recherche s√©mantique
**Collection**: Conversation

**Param√®tres**:
- `query` (str): Requ√™te en langage naturel
- `limit` (int): Nombre de r√©sultats (d√©faut 10)
- `category_filter` (str|None): Filtrer par cat√©gorie

**Retour**:
```json
{
  "results": [
    {
      "conversation_id": "chat_2026_01_09",
      "title": "Discussion on AI transformers",
      "summary": "Explained transformer architecture...",
      "category": "technical",
      "message_count": 24,
      "similarity": 0.89
    }
  ],
  "total_count": 10
}
```

**Usage**:
- Rechercher conversations pass√©es
- Retrouver discussions par th√®me
- Navigation s√©mantique

---

#### 18. `list_conversations(limit, category_filter)`
**Type**: Liste conversations
**Collection**: Conversation

**Param√®tres**:
- `limit` (int): Nombre max de r√©sultats (d√©faut 20)
- `category_filter` (str|None): Filtrer par cat√©gorie

**Retour**:
```json
{
  "conversations": [
    {
      "conversation_id": "chat_2026_01_09",
      "title": "Discussion on AI transformers",
      "category": "technical",
      "message_count": 24,
      "timestamp": "2026-01-09T10:00:00Z"
    }
  ],
  "total_count": 12
}
```

**Usage**:
- Explorer l'historique
- Lister par cat√©gorie
- Vue chronologique

---

## üìä R√©sum√© des Outils

| Cat√©gorie | Nombre | Collections utilis√©es | GPU Embedder |
|-----------|--------|----------------------|--------------|
| **Syst√®me** | 1 | - | - |
| **Library RAG** | 8 | Work, Chunk_v2, Summary_v2 | ‚úÖ |
| **Memory** | 9 | Thought, Message, Conversation | ‚úÖ |
| **TOTAL** | **18** | **6 collections** | **5 vectoris√©es** |

---

## üéØ Patterns d'Usage

### Pattern 1: Ingestion compl√®te
```python
# 1. Ing√©rer un PDF
result = parse_pdf("path/to/platon-menon.pdf")

# 2. V√©rifier l'ingestion
docs = list_documents(author_filter="Platon")

# 3. Rechercher dans le document
chunks = search_chunks("la vertu peut-elle s'enseigner", work_filter="M√©non")
```

### Pattern 2: Recherche multi-niveaux
```python
# 1. Recherche haut niveau (r√©sum√©s)
summaries = search_summaries("dialectique ma√Øeutique", limit=5)

# 2. Recherche d√©taill√©e (chunks)
chunks = search_chunks("dialectique ma√Øeutique", limit=20)
```

### Pattern 3: Exploration par auteur
```python
# 1. Lister les ≈ìuvres d'un auteur
author_data = filter_by_author("Platon")

# 2. R√©cup√©rer un document sp√©cifique
doc = get_document("platon-menon", include_toc=True)

# 3. Parcourir les chunks
chunks = get_chunks_by_document("platon-menon", limit=100)
```

### Pattern 4: Memory workflow
```python
# 1. Capturer une pens√©e
add_thought(
    content="Vector databases enable semantic search...",
    thought_type="observation",
    concepts=["weaviate", "embeddings"]
)

# 2. D√©marrer une conversation
add_message(
    content="Explain transformers",
    role="user",
    conversation_id="chat_2026_01_09"
)

# 3. Rechercher dans l'historique
messages = search_messages("transformers architecture")
```

---

## üîê S√©curit√©

### Validation des entr√©es
- Tous les param√®tres sont typ√©s avec Pydantic
- Validation automatique des limites (1-100 pour results)
- Filtrage SQL injection via Weaviate client

### Permissions
- `delete_document` n√©cessite `confirm=true` explicite
- Pas d'authentification (usage local Claude Desktop)
- Logs structur√©s JSON pour audit

### Error Handling
- `WeaviateConnectionError`: Probl√®me connexion base
- `PDFProcessingError`: √âchec traitement PDF
- Tous les outils retournent `success: false` + message d'erreur

---

## üöÄ Performance

### Latence typique
- `ping()`: <1ms
- `search_chunks()`: 100-500ms (vectorisation + recherche)
- `parse_pdf()`: 2-5min (d√©pend taille PDF, OCR, LLM)
- `list_documents()`: 50-100ms
- Memory tools: 100-300ms

### Optimisations
- GPU embedder (BAAI/bge-m3, RTX 4070): 17ms par query
- Weaviate HNSW + RQ: recherche <100ms sur 5k+ chunks
- Batch processing pour ingestion
- Cache Weaviate pour requ√™tes r√©p√©t√©es

---

## üìù Notes d'Impl√©mentation

### Architecture
- **Serveur**: FastMCP (stdio transport)
- **Handlers**: Fonctions async dans `mcp_tools/`
- **Memory handlers**: Dans `memory/mcp/`
- **Validation**: Pydantic models
- **Logging**: JSON structur√© avec timestamps

### Collections Weaviate
```
6 collections au total:

RAG (3):
- Work (no vectorizer) - 19 ≈ìuvres
- Chunk_v2 (GPU embedder) - 5,372 chunks
- Summary_v2 (GPU embedder) - 114 r√©sum√©s

Memory (3):
- Conversation (GPU embedder) - 12 conversations
- Message (GPU embedder) - 380 messages
- Thought (GPU embedder) - 104 pens√©es
```

### GPU Embedder
- **Mod√®le**: BAAI/bge-m3 (1024 dimensions)
- **Hardware**: RTX 4070 (PyTorch CUDA)
- **Performance**: 17ms par vectorisation
- **Context**: 8192 tokens
- **Usage**: Toutes les 5 collections vectoris√©es

---

## üéì Cas d'Usage

### 1. Recherche acad√©mique
- Ing√©rer corpus philosophique complet
- Recherche s√©mantique multi-≈ìuvres
- Analyse comparative auteurs/concepts

### 2. Aide √† la r√©daction
- Rechercher citations pertinentes
- Explorer arguments philosophiques
- Contextualiser concepts

### 3. Apprentissage
- Parcourir documents structur√©s (TOC)
- Recherche par niveaux (chapitres ‚Üí sections)
- D√©couverte guid√©e

### 4. M√©moire conversationnelle
- Capturer insights pendant recherche
- Historique conversations avec Claude
- Recherche transversale dans l'historique

---

**Derni√®re mise √† jour**: 2026-01-09
**Version**: Library RAG MCP Server v2.0
**Collections**: 6 (3 RAG + 3 Memory)
**GPU Embedder**: BAAI/bge-m3 (RTX 4070)
