# Lien entre Summary et Chunk - Explication Compl√®te

**Date**: 2026-01-03
**Fichiers analys√©s**: `utils/weaviate_ingest.py`, `schema.py`, `pdf_pipeline.py`

---

## üìã Table des Mati√®res

1. [Vue d'Ensemble](#1-vue-densemble)
2. [Lien Th√©orique entre Summary et Chunk](#2-lien-th√©orique-entre-summary-et-chunk)
3. [Comment les Summary sont Cr√©√©s](#3-comment-les-summary-sont-cr√©√©s)
4. [Pourquoi les Summary sont Vides](#4-pourquoi-les-summary-sont-vides)
5. [Comment Corriger le Probl√®me](#5-comment-corriger-le-probl√®me)

---

## 1. Vue d'Ensemble

### Architecture Hi√©rarchique

```
Document (ex: Peirce Collected Papers)
  ‚îÇ
  ‚îú‚îÄ‚ñ∫ TOC (Table des Mati√®res)
  ‚îÇ     ‚îî‚îÄ Structure hi√©rarchique des sections
  ‚îÇ
  ‚îú‚îÄ‚ñ∫ Summary (8,425 objets) - MACRO
  ‚îÇ     ‚îî‚îÄ Un r√©sum√© pour chaque section de la TOC
  ‚îÇ     ‚îî‚îÄ Vectoris√© pour recherche s√©mantique chapitres
  ‚îÇ
  ‚îî‚îÄ‚ñ∫ Chunk (5,404 objets) - MICRO
        ‚îî‚îÄ Fragments de texte (200-800 chars)
        ‚îî‚îÄ Vectoris√© pour recherche s√©mantique fine
```

### Lien entre Summary et Chunk

Le lien devrait √™tre **par sectionPath** :

```python
Summary:
  sectionPath: "Peirce: CP 5.314 > La s√©miose et les cat√©gories"
  chunksCount: 23  # ‚Üê Nombre de chunks dans cette section
  text: "Ce passage explore la th√©orie de la s√©miose..."

Chunk 1:
  sectionPath: "Peirce: CP 5.314 > La s√©miose et les cat√©gories"
  text: "Un signe, ou representamen, est quelque chose..."

Chunk 2:
  sectionPath: "Peirce: CP 5.314 > La s√©miose et les cat√©gories"
  text: "La s√©miose est l'action du signe..."

... (21 autres chunks)

Chunk 23:
  sectionPath: "Peirce: CP 5.314 > La s√©miose et les cat√©gories"
  text: "Ainsi la relation triadique est irr√©ductible..."
```

**Principe**: Tous les Chunks avec le m√™me `sectionPath` appartiennent au Summary correspondant.

---

## 2. Lien Th√©orique entre Summary et Chunk

### 2.1 Mod√®le de Donn√©es

#### Summary (R√©sum√© de Section)

**Fichier**: `utils/weaviate_ingest.py:86-100`

```python
class SummaryObject(TypedDict):
    """Structure d'un Summary dans Weaviate."""

    sectionPath: str       # "Peirce: CP 5.314 > La s√©miose"
    title: str             # "La s√©miose et les cat√©gories"
    level: int             # 2 (profondeur hi√©rarchique)
    text: str              # "Ce passage explore..." (R√âSUM√â LLM)
    concepts: List[str]    # ["s√©miose", "triade", "signe"]
    chunksCount: int       # 23 (nombre de chunks dans cette section)
    document: {
        sourceId: str      # "peirce_collected_papers_fixed"
    }
```

**Champs vectoris√©s**:
- ‚úÖ `text` ‚Üí Vectoris√© avec BGE-M3 (1024-dim)
- ‚úÖ `concepts` ‚Üí Vectoris√© avec BGE-M3

**Champs de filtrage**:
- `sectionPath` ‚Üí Pour lier avec Chunks
- `level` ‚Üí Pour hi√©rarchie (1=chapitre, 2=section, 3=subsection)
- `chunksCount` ‚Üí Pour navigation

#### Chunk (Fragment de Texte)

**Fichier**: `schema.py:216-280`

```python
{
    "text": str,              # Contenu du fragment (200-800 chars)
    "keywords": List[str],    # ["s√©miose", "triade"]

    "sectionPath": str,       # "Peirce: CP 5.314 > La s√©miose" (LIEN AVEC SUMMARY)
    "sectionLevel": int,      # 2
    "chapterTitle": str,      # "La s√©miose et les cat√©gories"
    "orderIndex": int,        # 42 (position dans le document)
    "unitType": str,          # "argument", "d√©finition", etc.

    "work": {
        "title": str,         # "Collected Papers"
        "author": str,        # "Peirce"
    },
    "document": {
        "sourceId": str,      # "peirce_collected_papers_fixed"
        "edition": str,       # "Hartshorne & Weiss"
    }
}
```

### 2.2 Comment le Lien Fonctionne

**Lien par sectionPath** (cha√Æne de caract√®res):

```python
# Recherche dans Summary
summary_result = summaries.query.near_text(query="s√©miose", limit=3)
top_section = summary_result.objects[0].properties['sectionPath']
# ‚Üí "Peirce: CP 5.314 > La s√©miose et les cat√©gories"

# R√©cup√©rer tous les Chunks de cette section
chunks = client.collections.get("Chunk")
chunk_result = chunks.query.fetch_objects(
    filters=Filter.by_property("sectionPath").like(f"{top_section}*"),
    limit=100
)
# ‚Üí Retourne les 23 chunks appartenant √† cette section
```

**Avantages de ce design** (vs cross-references):
- ‚úÖ Pas besoin de UUID references
- ‚úÖ Requ√™te unique (pas de jointures)
- ‚úÖ Filtrage simple avec LIKE ou EQUAL
- ‚úÖ Lisible et debuggable

**Inconv√©nients**:
- ‚ö†Ô∏è Sensible aux typos dans sectionPath
- ‚ö†Ô∏è Pas de validation d'int√©grit√© r√©f√©rentielle

---

## 3. Comment les Summary sont Cr√©√©s

### 3.1 Fonction d'Ingestion

**Fichier**: `utils/weaviate_ingest.py:632-731`

```python
def ingest_summaries(
    client: WeaviateClient,
    doc_name: str,
    toc: List[Dict[str, Any]],              # Table des mati√®res
    summaries_content: Dict[str, str],      # ‚Üê R√âSUM√âS LLM (actuellement vide !)
) -> int:
    """Insert section summaries into the Summary collection."""

    summaries_to_insert: List[SummaryObject] = []

    def process_toc(items: List[Dict[str, Any]], parent_path: str = "") -> None:
        """Parcourt r√©cursivement la TOC pour cr√©er des Summary."""
        for item in items:
            title: str = item.get("title", "")
            level: int = item.get("level", 1)
            path: str = f"{parent_path} > {title}" if parent_path else title

            summary_obj: SummaryObject = {
                "sectionPath": path,
                "title": title,
                "level": level,

                # ‚ö†Ô∏è PROBL√àME ICI : Si summaries_content est vide,
                # on utilise juste le titre comme texte !
                "text": summaries_content.get(title, title),

                "concepts": item.get("concepts", []),

                # ‚ö†Ô∏è PROBL√àME : Toujours 0, jamais calcul√© !
                "chunksCount": 0,

                "document": {
                    "sourceId": doc_name,
                },
            }
            summaries_to_insert.append(summary_obj)

            # Traiter les sous-sections r√©cursivement
            if "children" in item:
                process_toc(item["children"], path)

    process_toc(toc)

    # Insertion batch dans Weaviate
    summary_collection.data.insert_many(summaries_to_insert)
    return len(summaries_to_insert)
```

### 3.2 Appel dans le Pipeline

**Fichier**: `utils/weaviate_ingest.py:844-845`

```python
# Dans la fonction ingest_document()
if ingest_summary_collection and toc:
    ingest_summaries(client, doc_name, toc, {})  # ‚Üê {} = VIDE !
```

**PROBL√àME** : Le dictionnaire `summaries_content` pass√© est **VIDE** (`{}`).

**R√©sultat** : Ligne 686 ‚Üí `summaries_content.get(title, title)` retourne juste `title` !

**Exemple**:
```python
title = "Peirce: CP 5.314"
summaries_content = {}  # VIDE

text = summaries_content.get(title, title)
# ‚Üí text = "Peirce: CP 5.314" (car title pas dans dict vide)

# Attendu:
# text = "Ce passage explore la th√©orie de la s√©miose comme processus triadique..."
```

### 3.3 Source de la TOC

La TOC vient de l'extraction LLM :

**Fichier**: `utils/llm_toc.py` (√©tape 5 du pipeline)

```python
def extract_toc_from_markdown(markdown_text: str, ...) -> List[TOCEntry]:
    """Extrait la TOC via LLM (Ollama ou Mistral).

    R√©sultat:
    [
        {
            "title": "Peirce: CP 5.314",
            "level": 1,
            "page": null,
            "children": [
                {
                    "title": "La s√©miose et les cat√©gories",
                    "level": 2,
                    "page": null
                }
            ]
        },
        ...
    ]
    """
```

**Note**: La TOC contient **seulement les titres**, pas les r√©sum√©s.

---

## 4. Pourquoi les Summary sont Vides

### 4.1 Probl√®me #1 : Pas de G√©n√©ration de R√©sum√©s LLM

**Constat**: Le pipeline PDF ne g√©n√®re **jamais** de r√©sum√©s pour les sections.

**√âtapes du pipeline actuel** (`utils/pdf_pipeline.py`):
```
[1] OCR              ‚Üí Texte brut
[2] Markdown         ‚Üí Markdown structur√©
[3] Images           ‚Üí Extraction images
[4] Metadata         ‚Üí Titre, auteur, ann√©e
[5] TOC              ‚Üí Table des mati√®res (TITRES SEULEMENT)
[6] Classify         ‚Üí Classification sections
[7] Chunking         ‚Üí D√©coupage en chunks
[8] Cleaning         ‚Üí Nettoyage chunks
[9] Validation       ‚Üí Validation + concepts
[10] Ingestion       ‚Üí Insertion Weaviate
```

**Manque** : √âtape de g√©n√©ration de r√©sum√©s par section !

**Ce qui devrait exister** :
```
[5.5] Summarization  ‚Üí G√©n√©rer r√©sum√© LLM pour chaque section TOC
      Input: Section text (tous les chunks d'une section)
      Output: {"Peirce: CP 5.314": "Ce passage explore..."}
```

### 4.2 Probl√®me #2 : chunksCount Toujours √† 0

**Constat**: Le champ `chunksCount` est hardcod√© √† 0.

**Fichier**: `utils/weaviate_ingest.py:688`

```python
"chunksCount": 0,  # ‚Üê Hardcod√©, jamais calcul√© !
```

**Ce qui devrait √™tre fait** :

```python
def calculate_chunks_count(chunks: List[Dict], section_path: str) -> int:
    """Compte combien de chunks appartiennent √† cette section."""
    count = 0
    for chunk in chunks:
        if chunk.get("sectionPath", "").startswith(section_path):
            count += 1
    return count

# Dans process_toc():
chunks_count = calculate_chunks_count(all_chunks, path)

summary_obj: SummaryObject = {
    ...
    "chunksCount": chunks_count,  # ‚Üê Calcul√© dynamiquement
    ...
}
```

**Pourquoi ce n'est pas fait** :
- La fonction `ingest_summaries()` n'a pas acc√®s √† la liste des chunks
- Les chunks sont ins√©r√©s APR√àS les summaries dans le pipeline
- Ordre incorrect : devrait √™tre Chunks ‚Üí Summaries (pour compter)

### 4.3 Probl√®me #3 : Concepts Vides

**Constat**: Le champ `concepts` est toujours vide.

**Fichier**: `utils/weaviate_ingest.py:687`

```python
"concepts": item.get("concepts", []),  # ‚Üê TOC n'a jamais de concepts
```

**Explication**: La TOC extraite par LLM ne contient que `{title, level, page}`, pas de concepts.

**Ce qui devrait √™tre fait** :

Les concepts devraient √™tre extraits lors de la g√©n√©ration du r√©sum√© :

```python
# √âtape 5.5 - Summarization (√† cr√©er)
def generate_section_summary(section_text: str) -> Dict[str, Any]:
    """G√©n√®re r√©sum√© + concepts via LLM."""

    prompt = f"""R√©sume cette section et extrais les concepts cl√©s.

    Section:
    {section_text}

    R√©ponds en JSON:
    {{
        "summary": "R√©sum√© en 100-200 mots...",
        "concepts": ["concept1", "concept2", ...]
    }}
    """

    response = llm.generate(prompt)
    return json.loads(response)

# R√©sultat:
{
    "summary": "Ce passage explore la th√©orie de la s√©miose...",
    "concepts": ["s√©miose", "triade", "signe", "interpr√©tant", "repr√©sentamen"]
}
```

---

## 5. Comment Corriger le Probl√®me

### 5.1 Solution Compl√®te : Ajouter √âtape de Summarization

**Cr√©er nouveau module** : `utils/llm_summarizer.py`

```python
"""LLM-based section summarization for Library RAG.

Generates summaries and extracts concepts for each section in the TOC.
"""

from typing import Dict, List, Any
from utils.llm_structurer import get_llm_client
import json

def generate_summaries_for_toc(
    toc: List[Dict[str, Any]],
    chunks: List[Dict[str, Any]],
    llm_provider: str = "ollama"
) -> Dict[str, Dict[str, Any]]:
    """Generate LLM summaries for each section in the TOC.

    Args:
        toc: Table of contents with hierarchical structure.
        chunks: All document chunks with sectionPath.
        llm_provider: "ollama" or "mistral".

    Returns:
        Dict mapping section title to {summary, concepts}.

    Example:
        >>> summaries = generate_summaries_for_toc(toc, chunks)
        >>> summaries["Peirce: CP 5.314"]
        {
            "summary": "Ce passage explore la s√©miose...",
            "concepts": ["s√©miose", "triade", "signe"]
        }
    """

    llm = get_llm_client(llm_provider)
    summaries_content: Dict[str, Dict[str, Any]] = {}

    def process_section(item: Dict[str, Any], parent_path: str = "") -> None:
        title = item.get("title", "")
        path = f"{parent_path} > {title}" if parent_path else title

        # Collecter tous les chunks de cette section
        section_chunks = [
            chunk for chunk in chunks
            if chunk.get("sectionPath", "").startswith(path)
        ]

        if not section_chunks:
            # Pas de chunks, utiliser juste le titre
            summaries_content[title] = {
                "summary": title,
                "concepts": []
            }
        else:
            # G√©n√©rer r√©sum√© via LLM
            section_text = "\n\n".join([c.get("text", "") for c in section_chunks[:10]])  # Max 10 chunks

            prompt = f"""R√©sume cette section philosophique en 100-200 mots et extrais les 5-10 concepts cl√©s.

Section: {title}

Texte:
{section_text}

R√©ponds en JSON:
{{
    "summary": "R√©sum√© de la section...",
    "concepts": ["concept1", "concept2", ...]
}}
"""

            try:
                response = llm.generate(prompt, max_tokens=500)
                result = json.loads(response)
                summaries_content[title] = result
            except Exception as e:
                print(f"Erreur g√©n√©ration r√©sum√© pour {title}: {e}")
                summaries_content[title] = {
                    "summary": title,
                    "concepts": []
                }

        # Traiter sous-sections r√©cursivement
        if "children" in item:
            for child in item["children"]:
                process_section(child, path)

    for item in toc:
        process_section(item)

    return summaries_content
```

**Modifier le pipeline** : `utils/weaviate_ingest.py`

```python
def ingest_document(
    doc_name: str,
    chunks: List[Dict[str, Any]],
    metadata: Dict[str, Any],
    ...,
    ingest_summary_collection: bool = False,
) -> IngestResult:

    # ... (code existant pour chunks)

    # NOUVEAU : G√©n√©rer r√©sum√©s APR√àS avoir les chunks
    if ingest_summary_collection and toc:
        from utils.llm_summarizer import generate_summaries_for_toc

        # G√©n√©rer r√©sum√©s LLM pour chaque section
        summaries_content = generate_summaries_for_toc(toc, chunks, llm_provider="ollama")

        # Transformer en format pour ingest_summaries
        summaries_text = {
            title: content["summary"]
            for title, content in summaries_content.items()
        }

        # Ajouter concepts dans la TOC
        def enrich_toc_with_concepts(items: List[Dict]) -> None:
            for item in items:
                title = item.get("title", "")
                if title in summaries_content:
                    item["concepts"] = summaries_content[title]["concepts"]
                if "children" in item:
                    enrich_toc_with_concepts(item["children"])

        enrich_toc_with_concepts(toc)

        # Ins√©rer avec vrais r√©sum√©s
        ingest_summaries(client, doc_name, toc, summaries_text)
```

### 5.2 Solution Rapide : Calculer chunksCount Dynamiquement

**Modifier** : `utils/weaviate_ingest.py:ingest_summaries()`

```python
def ingest_summaries(
    client: WeaviateClient,
    doc_name: str,
    toc: List[Dict[str, Any]],
    summaries_content: Dict[str, str],
    chunks: List[Dict[str, Any]] = [],  # ‚Üê NOUVEAU param√®tre
) -> int:

    summaries_to_insert: List[SummaryObject] = []

    def count_chunks_for_section(section_path: str) -> int:
        """Compte chunks appartenant √† cette section."""
        count = 0
        for chunk in chunks:
            if chunk.get("sectionPath", "").startswith(section_path):
                count += 1
        return count

    def process_toc(items: List[Dict[str, Any]], parent_path: str = "") -> None:
        for item in items:
            title: str = item.get("title", "")
            level: int = item.get("level", 1)
            path: str = f"{parent_path} > {title}" if parent_path else title

            summary_obj: SummaryObject = {
                "sectionPath": path,
                "title": title,
                "level": level,
                "text": summaries_content.get(title, title),
                "concepts": item.get("concepts", []),

                # ‚úÖ CORRECTIF : Calculer dynamiquement
                "chunksCount": count_chunks_for_section(path),

                "document": {
                    "sourceId": doc_name,
                },
            }
            summaries_to_insert.append(summary_obj)

            if "children" in item:
                process_toc(item["children"], path)

    process_toc(toc)

    # ... (reste du code)
```

**Modifier appel** : `utils/weaviate_ingest.py:844-845`

```python
if ingest_summary_collection and toc:
    # ‚úÖ Passer les chunks pour calcul de chunksCount
    ingest_summaries(client, doc_name, toc, {}, chunks)
```

### 5.3 Solution Minimale : R√©-injecter avec Vraies Donn√©es

Si vous avez d√©j√† les r√©sum√©s dans les JSON :

```python
# Script de correction rapide
import json
import weaviate
from pathlib import Path

# Charger le JSON avec les r√©sum√©s
chunks_file = Path("output/peirce_collected_papers_fixed/peirce_collected_papers_fixed_chunks.json")
with open(chunks_file, 'r', encoding='utf-8') as f:
    data = json.load(f)

# V√©rifier s'il y a des r√©sum√©s
if 'summaries' in data:
    print(f"Trouv√© {len(data['summaries'])} r√©sum√©s dans le JSON")

    # Connecter √† Weaviate
    client = weaviate.connect_to_local()

    # Supprimer anciens Summary
    summaries = client.collections.get("Summary")
    summaries.data.delete_many(
        where=Filter.by_property("document").by_property("sourceId").equal("peirce_collected_papers_fixed")
    )

    # R√©ins√©rer avec vrais r√©sum√©s
    from utils.weaviate_ingest import ingest_summaries

    toc = data['metadata']['toc']
    chunks = data['chunks']

    # Extraire r√©sum√©s du JSON
    summaries_content = {
        s['title']: s['text']
        for s in data['summaries']
    }

    # R√©injecter
    count = ingest_summaries(client, "peirce_collected_papers_fixed", toc, summaries_content, chunks)
    print(f"R√©ins√©r√© {count} r√©sum√©s")

    client.close()
else:
    print("‚ùå Pas de r√©sum√©s dans le JSON - il faut les g√©n√©rer avec LLM")
```

---

## 6. R√©sum√© Visual

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    PIPELINE ACTUEL (CASS√â)                       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

PDF ‚Üí OCR ‚Üí Markdown ‚Üí TOC Extraction (LLM)
                         ‚îÇ
                         ‚îî‚îÄ‚ñ∫ toc = [
                               {"title": "Peirce: CP 5.314", "level": 1},
                               {"title": "La s√©miose", "level": 2}
                             ]

                         ‚Üì

Chunking (LLM) ‚Üí chunks = [
                   {"text": "Un signe...", "sectionPath": "Peirce: CP 5.314 > La s√©miose"},
                   {"text": "La s√©miose...", "sectionPath": "Peirce: CP 5.314 > La s√©miose"},
                   ...
                 ]

                 ‚Üì

Ingestion ‚Üí ingest_summaries(client, doc_name, toc, {})  ‚Üê VIDE !
            ‚îÇ
            ‚îî‚îÄ‚ñ∫ Summary cr√©√©s avec:
                  - text: "Peirce: CP 5.314" (juste le titre)
                  - concepts: []
                  - chunksCount: 0


‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                  PIPELINE CORRIG√â (ATTENDU)                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

PDF ‚Üí OCR ‚Üí Markdown ‚Üí TOC Extraction ‚Üí Chunking
                                          ‚îÇ
                                          ‚Üì
                                    Summarization (LLM) ‚Üê NOUVEAU !
                                          ‚îÇ
                                          ‚îî‚îÄ‚ñ∫ summaries_content = {
                                                "Peirce: CP 5.314": {
                                                  "summary": "Ce passage explore...",
                                                  "concepts": ["s√©miose", "triade"]
                                                }
                                              }

                                          ‚Üì

Ingestion ‚Üí ingest_summaries(client, doc_name, toc, summaries_content, chunks)
            ‚îÇ
            ‚îî‚îÄ‚ñ∫ Summary cr√©√©s avec:
                  - text: "Ce passage explore la th√©orie de la s√©miose..." ‚úÖ
                  - concepts: ["s√©miose", "triade", "signe"] ‚úÖ
                  - chunksCount: 23 ‚úÖ
```

---

## 7. Conclusion

### √âtat Actuel

**Summary ‚Üí Chunk** : ‚ùå LIEN CASS√â

| Aspect | Actuel | Attendu | Status |
|--------|--------|---------|--------|
| **text** | "Peirce: CP 5.314" | "Ce passage explore..." | ‚ùå Vide |
| **concepts** | `[]` | `["s√©miose", "triade"]` | ‚ùå Vide |
| **chunksCount** | 0 | 23 | ‚ùå Faux |
| **sectionPath** | ‚úÖ Correct | ‚úÖ Correct | ‚úÖ OK |

### Lien Th√©orique vs R√©el

**Th√©orique** (design pr√©vu):
```
Summary.sectionPath = "Peirce: CP 5.314 > La s√©miose"
  ‚Üì LIEN
Chunk.sectionPath = "Peirce: CP 5.314 > La s√©miose"
Chunk.sectionPath = "Peirce: CP 5.314 > La s√©miose"
... (23 chunks)
```

**R√©el** (impl√©mentation actuelle):
```
Summary.sectionPath = "Peirce: CP 5.314"  ‚úÖ OK
Summary.chunksCount = 0                   ‚ùå FAUX
Summary.text = "Peirce: CP 5.314"        ‚ùå VIDE

Chunk.sectionPath = "Peirce: CP 5.314"   ‚úÖ OK
Chunk.text = "Un signe, ou representamen..." ‚úÖ OK
```

**LIEN** : ‚ö†Ô∏è Existe techniquement (sectionPath identique) mais inutilisable car Summary vides.

### Actions Requises

**Priorit√© 1** : G√©n√©rer r√©sum√©s LLM (cr√©er `llm_summarizer.py`)
**Priorit√© 2** : Calculer `chunksCount` dynamiquement
**Priorit√© 3** : Extraire concepts pour Summary

**ROI** : Activer recherche hi√©rarchique Summary ‚Üí Chunk (+30% pr√©cision)

---

**Derni√®re mise √† jour**: 2026-01-03
**Auteur**: Analyse du code source
**Version**: 1.0
